{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "002e1c65",
   "metadata": {},
   "source": [
    "# Capstone: Employee Review Monitoring\n",
    "\n",
    "---\n",
    "\n",
    "#### 03a: <b>Modeling - Machine Learning</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea78c3c",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "- [Imports and functions](#Library-and-data-import)\n",
    "- [Initial Analysis](#Initial-analysis)\n",
    "- [Data Cleaning](#Data-cleaning)\n",
    "- [Exploratory Visualizations](#Exploratory-visualizations)\n",
    "- [Combine dataframes & feature engineer](#Combine-dataframes-&-feature-engineer)\n",
    "- [Export](#Export)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942db0a1",
   "metadata": {},
   "source": [
    "## Library and data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f36abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89fbb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_modeling = pd.read_csv(\"../data/train_modeling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "092a7529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30099, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined_text</th>\n",
       "      <th>v_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best Company to work for People are smart and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Moving at the speed of light, burn out is inev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great balance between big-company security and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The best place I've worked and also the most d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Execellent for engineers Impact driven. Best t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       combined_text  v_sentiment\n",
       "0  Best Company to work for People are smart and ...            1\n",
       "1  Moving at the speed of light, burn out is inev...            1\n",
       "2  Great balance between big-company security and...            1\n",
       "3  The best place I've worked and also the most d...            1\n",
       "4  Execellent for engineers Impact driven. Best t...            1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    27294\n",
      "-1     2578\n",
      " 0      227\n",
      "Name: v_sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_modeling.shape)\n",
    "display(df_modeling.head())\n",
    "print(df_modeling['v_sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d82133",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47723a1",
   "metadata": {},
   "source": [
    "### Changing 'Neutral' class to 'Negative'\n",
    "\n",
    "We will be changing the 'Neutral' class to be a 'Negative' class. This is because a neutral review made by an employee does contain a certain degree of organizational problems in addition to its positive aspects. Hence, in order to highlight these organizational problems, we would convert them as negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a573c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling['v_sentiment'] = df_modeling['v_sentiment'].replace([0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "317c6a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    27294\n",
       "-1     2805\n",
       "Name: v_sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modeling['v_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b27f69e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    27294\n",
       "0     2805\n",
       "Name: v_sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change 'Negative' to '0' label\n",
    "df_modeling['v_sentiment'] = df_modeling['v_sentiment'].replace([-1],0)\n",
    "\n",
    "df_modeling['v_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0d23f5",
   "metadata": {},
   "source": [
    "### Text normalization via Lemmatization\n",
    "\n",
    "When we normalize text, we attempt to reduce its randomness, bringing it closer to a predefined “standard”. This helps us to reduce the amount of different information that the computer has to deal with, and therefore improves efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c608b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v_sentiment</th>\n",
       "      <th>combined_text_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Best Company to work for People are smart and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Moving at the speed of light, burn out is inev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Great balance between big-company security and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The best place I've worked and also the most d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Execellent for engineer Impact driven. Best te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v_sentiment                                combined_text_lemma\n",
       "0            1  Best Company to work for People are smart and ...\n",
       "1            1  Moving at the speed of light, burn out is inev...\n",
       "2            1  Great balance between big-company security and...\n",
       "3            1  The best place I've worked and also the most d...\n",
       "4            1  Execellent for engineer Impact driven. Best te..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate tokernizer and lemmatizer\n",
    "w_tokenizer = WhitespaceTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to lemmatize words in dataframe\n",
    "def lemma_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "df_modeling['combined_text_lemma'] = df_modeling['combined_text'].\\\n",
    "                                        apply(lemma_text)\n",
    "\n",
    "# Join all words with one spacing\n",
    "df_modeling['combined_text_lemma'] = df_modeling['combined_text_lemma'].\\\n",
    "                                        apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Organize dataframe\n",
    "df_modeling.drop('combined_text',axis=1,inplace = True)\n",
    "df_modeling.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506540e3",
   "metadata": {},
   "source": [
    "### Customise stopwords\n",
    "\n",
    "Based on frequently appearing words in N-grams and WordCloud (done in EDA), we will be adding those words as new stopwords in the existing Sklearn stopwords package. \n",
    "\n",
    "Nltk's stopwords was chosen over Sklearn's stopwords due to Nltk being less comprehensive (almost twice the amount of stopwords as compared to Nltk's). Since sentiment analysis is involved, having a more comprehensive stopword list would result in a greater chance of altering the sentence such that the sentiment of the sentence might change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bb0f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default sklearn stopword list\n",
    "stop_words = stopwords.words('english')  \n",
    "\n",
    "# Add additional stopwords\n",
    "additional_stopwords = {'job','work','people','employee','company',\n",
    "                       'environment','life', 'wa','ha'}\n",
    "\n",
    "# Create custom stopword list\n",
    "my_stop_words = list(set().union(stop_words, additional_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb85616",
   "metadata": {},
   "source": [
    "### Train-validation-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc5e4e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input and output variables\n",
    "X = df_modeling['combined_text_lemma']\n",
    "y = df_modeling['v_sentiment']\n",
    "\n",
    "# Train-test-split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,\n",
    "                                                  y,\n",
    "                                                  stratify=y,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b414a80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Train Set Shape =====\n",
      "Features X_train: (22574,)\n",
      "Targets y_train:  (22574,)\n",
      "\n",
      "== Validation Set Shape ==\n",
      "Features X_val:   (7525,)\n",
      "Targets y_val:    (7525,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of training and testing vectors\n",
    "print(\" Train Set Shape \".center(27, \"=\"))\n",
    "print(f\"Features X_train: {X_train.shape}\")\n",
    "print(f\"Targets y_train:  {y_train.shape}\")\n",
    "print()\n",
    "print(\" Validation Set Shape \".center(26, \"=\"))\n",
    "print(f\"Features X_val:   {X_val.shape}\")\n",
    "print(f\"Targets y_val:    {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe2b68d",
   "metadata": {},
   "source": [
    "### Baseline Accuracy\n",
    "\n",
    "We need to calculate baseline accuracy in order to tell if our model is better than null model (predicting the plurality of class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "548c98f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.906844\n",
       "0    0.093156\n",
       "Name: v_sentiment, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a9ba35",
   "metadata": {},
   "source": [
    "## Modeling with SMOTE\n",
    "\n",
    "Due to the class imbalance of minority classes which is present in the training data, we applied SMOTE technique on the training set to oversample and balance the target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14658ef2",
   "metadata": {},
   "source": [
    "### Model Preparation\n",
    "\n",
    "**Workflow for this notebook:**\n",
    "- Transform data using vectorizer and SMOTE\n",
    "- Fit model (with hyperparameter tuning) to training data\n",
    "- Generate predictions using test data\n",
    "- Evaluate model based on evaluation metrics\n",
    "- Select best model\n",
    "\n",
    "**Vectorizers used:**\n",
    "\n",
    "`CountVectorizer` and `Tfidfvectorizer`\n",
    "\n",
    "**Models used:**\n",
    "\n",
    "`Multinomial Naïve Bayes`, `Logistic Regression`, `SVM`\n",
    "\n",
    "**Evaluation metrics used:**\n",
    "\n",
    "For machine learning models, ideally, we would want a high `specificity` for negative reviews (i.e. number of correctly predicted negative reviews) since being able to accurately predict negative reviews would give the company insights into organizational problems. We would also want a model that also does a good job correctly classifying positive reviews out of all the actual positive reviews, hence a high `precision` for positive reviews. \n",
    "\n",
    "We will also be using `Cohen's Kappa Statistic` which measures the proximity of the predicted classes to the actual classes when compared to a random classification. This is one of the best metrics for evaluating multi-class classifiers on imbalanced datasets. The closer the score to one, the better the classifier.\n",
    "\n",
    "---\n",
    "\n",
    "In notebook 3b, we will be running a `LSTM` model using TensorFlow Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f95fe6b",
   "metadata": {},
   "source": [
    "### Functions for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae7717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit GridSearch pipeline and generate best parameters\n",
    "def fit_rs(clf, params):\n",
    "    \"\"\"fits a RandomizedSearchCV to a classifier, prints best params and returns model\"\"\"\n",
    "    \n",
    "    # to optimize for scoring 'specificity' which is our primary metric\n",
    "    scoring = make_scorer(recall_score,pos_label=0)\n",
    "    rs = RandomizedSearchCV(clf, params, n_iter=100, cv=5, n_jobs=-1, scoring = scoring)\n",
    "    \n",
    "    # fit model\n",
    "    rs.fit(X_train, y_train)\n",
    "    \n",
    "    print(\" RandomizedSearchCV \".center(45, \"=\"))\n",
    "    print(f\"Best Parameters: {rs.best_params_}\")\n",
    "    print(f\"Best CV Score (Specificity): {rs.best_score_}\")\n",
    "    print()\n",
    "    print(\" Evaluation \".center(45, \"=\"))\n",
    "    print(\n",
    "        f\"Train Score: {rs.score(X_train, y_train)}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Testing Score: {rs.score(X_val, y_val)}\"\n",
    "    )\n",
    "\n",
    "    return rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c91fa5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate train/test accuracy & evaluation metrics\n",
    "def eval_model(model):\n",
    "    \"\"\"returns dataframe of evaluation metrics for classifier\"\"\"\n",
    "\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_val)\n",
    "#     y_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    randomcv = model.best_score_\n",
    "    \n",
    "    # Metrics for evaluating classifier\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "\n",
    "    accuracy = (tn + tp) / (tn + fp + fn + tp)\n",
    "    \n",
    "    print(classification_report(y_val, y_pred, digits =3))\n",
    "    \n",
    "#     if (tn + fp) != 0:\n",
    "#         spec = tn / (tn + fp)\n",
    "#     else:\n",
    "#         spec = \"NA\"\n",
    "\n",
    "    if (tp + fn) != 0:\n",
    "        recall = tp / (tp + fn)\n",
    "    else:\n",
    "        recall = np.nan\n",
    "\n",
    "    if (tp + fp) != 0:\n",
    "        precision = tp / (tp + fp)\n",
    "    else:\n",
    "        precision = np.nan\n",
    "\n",
    "    if recall == np.nan or precision == np.nan:\n",
    "        f1 = np.nan\n",
    "    else:\n",
    "        f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    \n",
    "    \n",
    "    ck = cohen_kappa_score(y_val, y_pred)\n",
    "\n",
    "    try:\n",
    "        model_name = str(model.estimator)[:-2]\n",
    "        if len(model_name) > 30:\n",
    "            model_name = model_name[:13]\n",
    "    except:\n",
    "        model_name = \"Dummy\"\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        [np.round([randomcv, accuracy, recall, \n",
    "                   precision, f1, \n",
    "                   ck, fp, \n",
    "                   fn], 3)],\n",
    "        columns=[\n",
    "            \"Best CV Score (specificity)\",\n",
    "            \"Accuracy\",\n",
    "            \"Recall\",\n",
    "            \"Precision\",\n",
    "            \"F1\",\n",
    "            \"Cohen Kappa\",\n",
    "            \"False Positives\",\n",
    "            \"False Negatives\"\n",
    "        ],\n",
    "        index=[model_name],\n",
    "        dtype=\"str\",\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdc5fea",
   "metadata": {},
   "source": [
    "### Naïve Bayes [Benchmark Model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f59cfd",
   "metadata": {},
   "source": [
    "Naïve Bayes classifier is a probabilistic machine learning model that is commonly used in classification problems. It relies on Bayes Theorem, which is a way of finding a probability when we know certain other probabilities. In this case, we want to calculate the probability that a review is classified under `Positive (1)` or `Negative (-1)` given the words in the 'combined_text' column.\n",
    "\n",
    "We will be using `Multinomial Naive Bayes` bacause it works with occurrence counts (features are positive discrete integers), while Bernoullii Naive Bayes is designed for binaary/boolean features.\n",
    "\n",
    "However, limitations of the Naive Bayes model is that it makes the assumption that all features are independent of one another in which text data is never independent (i.e. certain words can change the context of a sentence when used with other words. \n",
    "\n",
    "Despite this assumption not being realistic with NLP data, we still use Naïve Bayes pretty frequently.\n",
    "- It's a very fast modeling algorithm (which is great especially when we have lots of features and/or lots of data!).\n",
    "- It is often an excellent classifier, outperforming more complicated models.\n",
    "- Very useful for text processing\n",
    "\n",
    "Hence, this would be our **benchmark model**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058a6a98",
   "metadata": {},
   "source": [
    "### Multinomial NB (CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4985d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for vectorizer and estimator\n",
    "# Pipeline is from imblearn and not sklearn, in order to apply SMOTE\n",
    "pipe1 = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4a21c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('cvec', CountVectorizer()),\n",
       "  ('smote', SMOTE(random_state=42)),\n",
       "  ('nb', MultinomialNB())],\n",
       " 'verbose': False,\n",
       " 'cvec': CountVectorizer(),\n",
       " 'smote': SMOTE(random_state=42),\n",
       " 'nb': MultinomialNB(),\n",
       " 'cvec__analyzer': 'word',\n",
       " 'cvec__binary': False,\n",
       " 'cvec__decode_error': 'strict',\n",
       " 'cvec__dtype': numpy.int64,\n",
       " 'cvec__encoding': 'utf-8',\n",
       " 'cvec__input': 'content',\n",
       " 'cvec__lowercase': True,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__preprocessor': None,\n",
       " 'cvec__stop_words': None,\n",
       " 'cvec__strip_accents': None,\n",
       " 'cvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'cvec__tokenizer': None,\n",
       " 'cvec__vocabulary': None,\n",
       " 'smote__k_neighbors': 5,\n",
       " 'smote__n_jobs': None,\n",
       " 'smote__random_state': 42,\n",
       " 'smote__sampling_strategy': 'auto',\n",
       " 'nb__alpha': 1.0,\n",
       " 'nb__class_prior': None,\n",
       " 'nb__fit_prior': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualise all parameters available for tuning\n",
    "pipe1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad2d4143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "pipe_params1 = {\n",
    "    'cvec__max_features': [None], # selecting top N words from entire corpus\n",
    "    'cvec__min_df':[2,3,4], # word must occur in at least N documents in corpus\n",
    "    'cvec__max_df':[0.5,0.6,0.4], # ignore words that occur in >N% of the documents in corpus\n",
    "    'cvec__ngram_range': [(1,1), (1,2)], # words from unigram / words from unigram + bigram\n",
    "    'cvec__stop_words': [my_stop_words, None], # stopwords from sklearn + custom words\n",
    "    'smote__k_neighbors': [4,5,6],\n",
    "    'nb__fit_prior': [True, False],\n",
    "    'nb__alpha': [1] # additive smoothing parameter\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29fcb559",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= RandomizedSearchCV ============\n",
      "Best Parameters: {'smote__k_neighbors': 6, 'nb__fit_prior': False, 'nb__alpha': 1, 'cvec__stop_words': ['before', 'she', \"don't\", \"mustn't\", 'than', 'they', 'further', 'more', 'too', 'll', 're', \"weren't\", \"shouldn't\", 'some', \"doesn't\", 'these', 'am', 'is', 'our', 'o', 'only', 'down', 'shouldn', 'at', 'no', 'doesn', 'yours', \"wasn't\", \"haven't\", 'each', 'aren', 'just', 'hers', 'mustn', 'shan', 'the', 'above', 'why', 'between', 'under', \"isn't\", 'that', 'ma', 'be', 'its', 'once', 'most', 'against', 'ourselves', 'until', 'so', 'my', 'off', \"you'll\", 'd', 'up', 'mightn', 's', 'on', 'him', 'themselves', 'ours', 'myself', 'very', 'hadn', \"hasn't\", 'you', 'from', \"you'd\", 'them', 'had', 'what', 'for', 'can', 'do', 'isn', 'by', 'was', 'having', \"mightn't\", 'couldn', \"you've\", 'to', \"it's\", 'yourself', 'itself', 'environment', \"couldn't\", 'work', 'other', 'ain', 'it', \"wouldn't\", 'life', 'were', 'people', 'm', 'how', 'now', 'should', 'your', 'wa', 'both', 'wouldn', 'over', 'hasn', 'did', 'i', 'such', 've', 'there', 'again', 'any', 'me', 'if', 'where', 'not', 't', \"you're\", 'doing', 'y', 'don', 'weren', 'into', \"aren't\", 'he', 'his', 'employee', 'himself', 'when', 'as', 'about', 'during', 'out', 'all', 'through', 'yourselves', 'has', 'whom', 'company', 'here', \"she's\", 'after', \"hadn't\", 'while', 'didn', 'because', 'haven', 'a', 'job', 'are', 'in', 'which', 'won', \"didn't\", 'will', \"shan't\", 'wasn', 'who', 'have', 'their', \"won't\", 'nor', 'needn', 'or', 'herself', 'then', 'we', 'this', 'been', 'theirs', 'same', 'does', \"that'll\", 'below', 'of', 'those', \"needn't\", 'an', 'few', 'own', 'and', 'ha', \"should've\", 'her', 'with', 'being', 'but'], 'cvec__ngram_range': (1, 2), 'cvec__min_df': 4, 'cvec__max_features': None, 'cvec__max_df': 0.5}\n",
      "Best CV Score (Specificity): 0.5018923198733176\n",
      "\n",
      "================= Evaluation ================\n",
      "Train Score: 0.776615969581749\n",
      "Testing Score: 0.4992867332382311\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "mnb_cvec = fit_rs(pipe1, pipe_params1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6826122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.362     0.499     0.420       701\n",
      "           1      0.946     0.910     0.928      6824\n",
      "\n",
      "    accuracy                          0.871      7525\n",
      "   macro avg      0.654     0.704     0.674      7525\n",
      "weighted avg      0.892     0.871     0.880      7525\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best CV Score (specificity)</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Cohen Kappa</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pipeline(step</th>\n",
       "      <td>0.502</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.349</td>\n",
       "      <td>351.0</td>\n",
       "      <td>617.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Best CV Score (specificity) Accuracy Recall Precision     F1  \\\n",
       "Pipeline(step                       0.502    0.871   0.91     0.946  0.928   \n",
       "\n",
       "              Cohen Kappa False Positives False Negatives  \n",
       "Pipeline(step       0.349           351.0           617.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_cvec_res = eval_model(mnb_cvec)\n",
    "mnb_cvec_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c235343",
   "metadata": {},
   "source": [
    "### Multinomial NB (TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c017c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for vectorizer and estimator\n",
    "pipe2 = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ec7a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params2 = {\n",
    "    'tvec__max_features': [None],\n",
    "    'tvec__min_df':[3,4,5],\n",
    "    'tvec__max_df':[0.5,0.6,0.4],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)],\n",
    "    'tvec__stop_words': [my_stop_words, None],\n",
    "    'smote__k_neighbors': [4,5,3],\n",
    "    'nb__fit_prior': [True, False],\n",
    "    'nb__alpha': [1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96bcc1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= RandomizedSearchCV ============\n",
      "Best Parameters: {'tvec__stop_words': ['before', 'she', \"don't\", \"mustn't\", 'than', 'they', 'further', 'more', 'too', 'll', 're', \"weren't\", \"shouldn't\", 'some', \"doesn't\", 'these', 'am', 'is', 'our', 'o', 'only', 'down', 'shouldn', 'at', 'no', 'doesn', 'yours', \"wasn't\", \"haven't\", 'each', 'aren', 'just', 'hers', 'mustn', 'shan', 'the', 'above', 'why', 'between', 'under', \"isn't\", 'that', 'ma', 'be', 'its', 'once', 'most', 'against', 'ourselves', 'until', 'so', 'my', 'off', \"you'll\", 'd', 'up', 'mightn', 's', 'on', 'him', 'themselves', 'ours', 'myself', 'very', 'hadn', \"hasn't\", 'you', 'from', \"you'd\", 'them', 'had', 'what', 'for', 'can', 'do', 'isn', 'by', 'was', 'having', \"mightn't\", 'couldn', \"you've\", 'to', \"it's\", 'yourself', 'itself', 'environment', \"couldn't\", 'work', 'other', 'ain', 'it', \"wouldn't\", 'life', 'were', 'people', 'm', 'how', 'now', 'should', 'your', 'wa', 'both', 'wouldn', 'over', 'hasn', 'did', 'i', 'such', 've', 'there', 'again', 'any', 'me', 'if', 'where', 'not', 't', \"you're\", 'doing', 'y', 'don', 'weren', 'into', \"aren't\", 'he', 'his', 'employee', 'himself', 'when', 'as', 'about', 'during', 'out', 'all', 'through', 'yourselves', 'has', 'whom', 'company', 'here', \"she's\", 'after', \"hadn't\", 'while', 'didn', 'because', 'haven', 'a', 'job', 'are', 'in', 'which', 'won', \"didn't\", 'will', \"shan't\", 'wasn', 'who', 'have', 'their', \"won't\", 'nor', 'needn', 'or', 'herself', 'then', 'we', 'this', 'been', 'theirs', 'same', 'does', \"that'll\", 'below', 'of', 'those', \"needn't\", 'an', 'few', 'own', 'and', 'ha', \"should've\", 'her', 'with', 'being', 'but'], 'tvec__ngram_range': (1, 2), 'tvec__min_df': 5, 'tvec__max_features': None, 'tvec__max_df': 0.5, 'smote__k_neighbors': 4, 'nb__fit_prior': False, 'nb__alpha': 1}\n",
      "Best CV Score (Specificity): 0.6078769369980772\n",
      "\n",
      "================= Evaluation ================\n",
      "Train Score: 0.938212927756654\n",
      "Testing Score: 0.6219686162624821\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "mnb_tvec = fit_rs(pipe2, pipe_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abd4c860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.327     0.622     0.428       701\n",
      "           1      0.957     0.868     0.911      6824\n",
      "\n",
      "    accuracy                          0.845      7525\n",
      "   macro avg      0.642     0.745     0.669      7525\n",
      "weighted avg      0.898     0.845     0.866      7525\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best CV Score (specificity)</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Cohen Kappa</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pipeline(step</th>\n",
       "      <td>0.608</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.349</td>\n",
       "      <td>265.0</td>\n",
       "      <td>899.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Best CV Score (specificity) Accuracy Recall Precision     F1  \\\n",
       "Pipeline(step                       0.608    0.845  0.868     0.957  0.911   \n",
       "\n",
       "              Cohen Kappa False Positives False Negatives  \n",
       "Pipeline(step       0.349           265.0           899.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_tvec_res = eval_model(mnb_tvec)\n",
    "mnb_tvec_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b8913b",
   "metadata": {},
   "source": [
    "### Logistic Regression (CountVectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfa75a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for vectorizer and estimator\n",
    "pipe3 = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('smote', SMOTE(random_state = 42)),\n",
    "    ('logreg', LogisticRegression(random_state = 42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f613a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params3 = {\n",
    "    'cvec__max_features': [None],\n",
    "    'cvec__min_df':[2,3,4],\n",
    "    'cvec__max_df':[0.5,0.6,0.4],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'cvec__stop_words': [my_stop_words, None],\n",
    "    'smote__k_neighbors': [4,5,6],\n",
    "    'logreg__C': [10e-1, 10e0, 10e1],\n",
    "    'logreg__penalty': [\"l1\", \"l2\"],\n",
    "    'logreg__max_iter': [50, 100, 200],\n",
    "    'logreg__solver': [\"liblinear\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59fe0e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= RandomizedSearchCV ============\n",
      "Best Parameters: {'smote__k_neighbors': 4, 'logreg__solver': 'liblinear', 'logreg__penalty': 'l1', 'logreg__max_iter': 50, 'logreg__C': 1.0, 'cvec__stop_words': None, 'cvec__ngram_range': (1, 1), 'cvec__min_df': 2, 'cvec__max_features': None, 'cvec__max_df': 0.5}\n",
      "Best CV Score (Specificity): 0.5731919466123742\n",
      "\n",
      "================= Evaluation ================\n",
      "Train Score: 0.8236692015209125\n",
      "Testing Score: 0.6034236804564908\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "logreg_cvec = fit_rs(pipe3, pipe_params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ef5edd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.505     0.603     0.550       701\n",
      "           1      0.958     0.939     0.949      6824\n",
      "\n",
      "    accuracy                          0.908      7525\n",
      "   macro avg      0.732     0.771     0.749      7525\n",
      "weighted avg      0.916     0.908     0.912      7525\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best CV Score (specificity)</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Cohen Kappa</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pipeline(step</th>\n",
       "      <td>0.573</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.499</td>\n",
       "      <td>278.0</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Best CV Score (specificity) Accuracy Recall Precision     F1  \\\n",
       "Pipeline(step                       0.573    0.908  0.939     0.958  0.949   \n",
       "\n",
       "              Cohen Kappa False Positives False Negatives  \n",
       "Pipeline(step       0.499           278.0           414.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cvec_res = eval_model(logreg_cvec)\n",
    "logreg_cvec_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7756d",
   "metadata": {},
   "source": [
    "### Logistic Regression (TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af6a889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for vectorizer and estimator\n",
    "pipe4 = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('smote', SMOTE(random_state = 42)),\n",
    "    ('logreg', LogisticRegression(random_state = 42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee82a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params4 = {\n",
    "    'tvec__max_features': [None],\n",
    "    'tvec__min_df':[3,4,5],\n",
    "    'tvec__max_df':[0.5,0.6,0.4],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)],\n",
    "    'tvec__stop_words': [my_stop_words, None],\n",
    "    'smote__k_neighbors': [4,5,3],\n",
    "    'logreg__C': [10e-1, 10e0, 10e1],\n",
    "    'logreg__penalty': [\"l1\", \"l2\"],\n",
    "    'logreg__max_iter': [50, 100, 200],\n",
    "    'logreg__solver': [\"liblinear\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58bc7464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= RandomizedSearchCV ============\n",
      "Best Parameters: {'tvec__stop_words': None, 'tvec__ngram_range': (1, 2), 'tvec__min_df': 4, 'tvec__max_features': None, 'tvec__max_df': 0.5, 'smote__k_neighbors': 5, 'logreg__solver': 'liblinear', 'logreg__penalty': 'l1', 'logreg__max_iter': 200, 'logreg__C': 1.0}\n",
      "Best CV Score (Specificity): 0.7542744033480375\n",
      "\n",
      "================= Evaluation ================\n",
      "Train Score: 0.9315589353612167\n",
      "Testing Score: 0.7617689015691869\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "logreg_tvec = fit_rs(pipe4, pipe_params4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "704cdf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.507     0.762     0.609       701\n",
      "           1      0.974     0.924     0.948      6824\n",
      "\n",
      "    accuracy                          0.909      7525\n",
      "   macro avg      0.741     0.843     0.779      7525\n",
      "weighted avg      0.931     0.909     0.917      7525\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best CV Score (specificity)</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Cohen Kappa</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pipeline(step</th>\n",
       "      <td>0.754</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.56</td>\n",
       "      <td>167.0</td>\n",
       "      <td>519.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Best CV Score (specificity) Accuracy Recall Precision     F1  \\\n",
       "Pipeline(step                       0.754    0.909  0.924     0.974  0.948   \n",
       "\n",
       "              Cohen Kappa False Positives False Negatives  \n",
       "Pipeline(step        0.56           167.0           519.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_tvec_res = eval_model(logreg_tvec)\n",
    "logreg_tvec_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc2f31",
   "metadata": {},
   "source": [
    "### Support Vector Machine Classifier (CountVectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03733a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for vectorizer and estimator\n",
    "pipe5 = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('smote', SMOTE(random_state = 42)),\n",
    "    ('svc', SVC(random_state = 42, max_iter = 2000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25cd299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params5 = {\n",
    "    'cvec__max_features': [None],\n",
    "    'cvec__min_df':[2,3,4],\n",
    "    'cvec__max_df':[0.5,0.6,0.4],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'cvec__stop_words': [my_stop_words, None],\n",
    "    'smote__k_neighbors': [4,5,6],\n",
    "    'svc__C': [10e-1, 10e0, 10e1],\n",
    "    'svc__kernel': ['rbf','poly'],\n",
    "    'svc__degree': [2,3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41f90068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JunnYiow/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= RandomizedSearchCV ============\n",
      "Best Parameters: {'svc__kernel': 'rbf', 'svc__degree': 3, 'svc__C': 100.0, 'smote__k_neighbors': 5, 'cvec__stop_words': None, 'cvec__ngram_range': (1, 1), 'cvec__min_df': 4, 'cvec__max_features': None, 'cvec__max_df': 0.5}\n",
      "Best CV Score (Specificity): 0.5874799230856238\n",
      "\n",
      "================= Evaluation ================\n",
      "Train Score: 0.9795627376425855\n",
      "Testing Score: 0.6419400855920114\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "svc_cvec = fit_rs(pipe5, pipe_params5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f79cdf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.268     0.642     0.379       701\n",
      "           1      0.957     0.820     0.883      6824\n",
      "\n",
      "    accuracy                          0.804      7525\n",
      "   macro avg      0.613     0.731     0.631      7525\n",
      "weighted avg      0.893     0.804     0.836      7525\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best CV Score (specificity)</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Cohen Kappa</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pipeline(step</th>\n",
       "      <td>0.587</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.285</td>\n",
       "      <td>251.0</td>\n",
       "      <td>1226.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Best CV Score (specificity) Accuracy Recall Precision     F1  \\\n",
       "Pipeline(step                       0.587    0.804   0.82     0.957  0.883   \n",
       "\n",
       "              Cohen Kappa False Positives False Negatives  \n",
       "Pipeline(step       0.285           251.0          1226.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_cvec_res = eval_model(svc_cvec)\n",
    "svc_cvec_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d3451",
   "metadata": {},
   "source": [
    "### Support Vector Machine Classifier (TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bfb3ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for vectorizer and estimator\n",
    "pipe6 = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('smote', SMOTE(random_state = 42)),\n",
    "    ('svc', SVC(random_state = 42, max_iter = 2000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99604ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params6 = {\n",
    "    'tvec__max_features': [None],\n",
    "    'tvec__min_df':[3,4,5],\n",
    "    'tvec__max_df':[0.5,0.6,0.4],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)],\n",
    "    'tvec__stop_words': [my_stop_words, None],\n",
    "    'smote__k_neighbors': [4,5,3],\n",
    "    'svc__C': [10e-1, 10e0, 10e1],\n",
    "    'svc__kernel': ['rbf','poly'],\n",
    "    'svc__degree': [2,3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "061430d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JunnYiow/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= RandomizedSearchCV ============\n",
      "Best Parameters: {'tvec__stop_words': None, 'tvec__ngram_range': (1, 2), 'tvec__min_df': 3, 'tvec__max_features': None, 'tvec__max_df': 0.4, 'svc__kernel': 'poly', 'svc__degree': 3, 'svc__C': 10.0, 'smote__k_neighbors': 5}\n",
      "Best CV Score (Specificity): 1.0\n",
      "\n",
      "================= Evaluation ================\n",
      "Train Score: 1.0\n",
      "Testing Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "svc_tvec = fit_rs(pipe6, pipe_params6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a7146e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.094     1.000     0.171       701\n",
      "           1      1.000     0.005     0.010      6824\n",
      "\n",
      "    accuracy                          0.098      7525\n",
      "   macro avg      0.547     0.502     0.091      7525\n",
      "weighted avg      0.916     0.098     0.025      7525\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best CV Score (specificity)</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Cohen Kappa</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pipeline(step</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6790.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Best CV Score (specificity) Accuracy Recall Precision    F1  \\\n",
       "Pipeline(step                         1.0    0.098  0.005       1.0  0.01   \n",
       "\n",
       "              Cohen Kappa False Positives False Negatives  \n",
       "Pipeline(step       0.001             0.0          6790.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_tvec_res = eval_model(svc_tvec)\n",
    "svc_tvec_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a2e8bd",
   "metadata": {},
   "source": [
    "## Evaluating and Interpreting Results\n",
    "\n",
    "### Summary of results for above models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c468114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary results without oversampling\n",
    "summary = pd.concat(\n",
    "    [\n",
    "        mnb_cvec_res,\n",
    "        mnb_tvec_res,\n",
    "        logreg_cvec_res,\n",
    "        logreg_tvec_res,\n",
    "        svc_cvec_res,\n",
    "        svc_tvec_res\n",
    "    ]\n",
    ")\n",
    "\n",
    "summary.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02282595",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.rename({0: 'MNB-CVEC',\n",
    "                1: 'MNB-TFIDF',\n",
    "               2: 'LR-CVEC',\n",
    "               3: 'LR-TFIDF',\n",
    "               4: 'SVC-CVEC',\n",
    "               5: 'SVC-TFIDF'}, axis='index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "36cc38d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best CV Score (specificity)</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Cohen Kappa</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC-TFIDF</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6790.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR-TFIDF</th>\n",
       "      <td>0.754</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.56</td>\n",
       "      <td>167.0</td>\n",
       "      <td>519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNB-TFIDF</th>\n",
       "      <td>0.608</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.349</td>\n",
       "      <td>265.0</td>\n",
       "      <td>899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-CVEC</th>\n",
       "      <td>0.587</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.285</td>\n",
       "      <td>251.0</td>\n",
       "      <td>1226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR-CVEC</th>\n",
       "      <td>0.573</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.499</td>\n",
       "      <td>278.0</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNB-CVEC</th>\n",
       "      <td>0.502</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.349</td>\n",
       "      <td>351.0</td>\n",
       "      <td>617.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Best CV Score (specificity) Accuracy Recall Precision     F1  \\\n",
       "SVC-TFIDF                         1.0    0.098  0.005       1.0   0.01   \n",
       "LR-TFIDF                        0.754    0.909  0.924     0.974  0.948   \n",
       "MNB-TFIDF                       0.608    0.845  0.868     0.957  0.911   \n",
       "SVC-CVEC                        0.587    0.804   0.82     0.957  0.883   \n",
       "LR-CVEC                         0.573    0.908  0.939     0.958  0.949   \n",
       "MNB-CVEC                        0.502    0.871   0.91     0.946  0.928   \n",
       "\n",
       "          Cohen Kappa False Positives False Negatives  \n",
       "SVC-TFIDF       0.001             0.0          6790.0  \n",
       "LR-TFIDF         0.56           167.0           519.0  \n",
       "MNB-TFIDF       0.349           265.0           899.0  \n",
       "SVC-CVEC        0.285           251.0          1226.0  \n",
       "LR-CVEC         0.499           278.0           414.0  \n",
       "MNB-CVEC        0.349           351.0           617.0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.sort_values(by=['Best CV Score (specificity)'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dc5a361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"lr_tfidf.pkl\", mode = \"wb\")\n",
    "pickle.dump(logreg_tvec, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d309b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
